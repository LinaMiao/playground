{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named findspark",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f1c689713d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named findspark"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = '/Users/linamiao/playground/spark/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([-0.5556, 0.5]), label=0.0),\n",
       " Row(features=DenseVector([-0.8333, 0.0]), label=0.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisTwoFeatures = sqlContext.read.parquet(basedir + 'irisTwoFeatures.parquet')\n",
    "irisTwoFeatures.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([-0.5556, 0.5]), label=0.0, sepalLength=-0.555556, sepalWidth=0.5),\n",
       " Row(features=DenseVector([-0.8333, 0.0]), label=0.0, sepalLength=-0.833333, sepalWidth=0.0),\n",
       " Row(features=DenseVector([-0.4444, 0.4167]), label=0.0, sepalLength=-0.444444, sepalWidth=0.416667),\n",
       " Row(features=DenseVector([-0.6111, 0.0833]), label=0.0, sepalLength=-0.611111, sepalWidth=0.0833333),\n",
       " Row(features=DenseVector([0.5, 0.0]), label=1.0, sepalLength=0.5, sepalWidth=0.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "getElement = udf(lambda v, i: float(v[i]), DoubleType())\n",
    "irisSeparateFeatures = (irisTwoFeatures\n",
    "                           .withColumn('sepalLength', getElement('features',lit(0)))\n",
    "                           .withColumn('sepalWidth', getElement('features',lit(1))))\n",
    "irisSeparateFeatures.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\"Can't extract value from features#252;\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "try:\n",
    "    irisTwoFeatures.withColumn('sepalLength', col('features').getItem(0)).take(5)\n",
    "except AnalysisException as e:\n",
    "    print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  anArray|\n",
      "+---------+\n",
      "|[1, 2, 3]|\n",
      "|   [4, 5]|\n",
      "+---------+\n",
      "\n",
      "+----------+\n",
      "|anArray[0]|\n",
      "+----------+\n",
      "|         1|\n",
      "|         4|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|anArray[0]|\n",
      "+----------+\n",
      "|         1|\n",
      "|         4|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "arrayDF = sqlContext.createDataFrame([Row(anArray=[1,2,3]),Row(anArray=[4,5])])\n",
    "arrayDF.take(2)\n",
    "arrayDF.show()\n",
    "\n",
    "arrayDF.select(col('anArray').getItem(0)).show()\n",
    "arrayDF.select(col('anArray')[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.udf.register('getElement',getElement.func,getElement.returnType)\n",
    "irisTwoFeatures.registerTempTable('irisTwo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sepalLength|\n",
      "+-----------+\n",
      "|  -0.555556|\n",
      "|  -0.833333|\n",
      "|  -0.444444|\n",
      "|  -0.611111|\n",
      "|        0.5|\n",
      "|   0.166667|\n",
      "|   0.444444|\n",
      "|  -0.333333|\n",
      "|  -0.555556|\n",
      "|  -0.666667|\n",
      "|  -0.777778|\n",
      "|  -0.833333|\n",
      "|  -0.611111|\n",
      "|  -0.388889|\n",
      "|  -0.833333|\n",
      "|  -0.611111|\n",
      "|  0.0555554|\n",
      "|  -0.555556|\n",
      "|  -0.222222|\n",
      "|   0.111111|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select getElement(features, 0) as sepalLength from irisTwo').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and feature enginerring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+\n",
      "|summary|             label|         sepalLength|          sepalWidth|\n",
      "+-------+------------------+--------------------+--------------------+\n",
      "|  count|               150|                 150|                 150|\n",
      "|   mean|               1.0|-0.14259263863153332|-0.12166668000000001|\n",
      "| stddev|0.8192319205190404|  0.4600366943839747|  0.3613285840513614|\n",
      "|    min|               0.0|                -1.0|                -1.0|\n",
      "|    max|               2.0|                 1.0|                 1.0|\n",
      "+-------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisSeparateFeatures.describe('label','sepalLength','sepalWidth').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (current: features)\n",
      "outputCol: output column name. (default: StandardScaler_4a869ac3b8bd6b81d740__output, current: standardized)\n",
      "withMean: Center data with mean (default: False, current: True)\n",
      "withStd: Scale to unit standard deviation (default: True)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "standardScaler = (StandardScaler()\n",
    "                      .setInputCol('features')\n",
    "                      .setOutputCol('standardized')\n",
    "                      .setWithMean(True))\n",
    "print standardScaler.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------------+--------------------+\n",
      "|            features|label|sepalLength|sepalWidth|        standardized|   standadizedLength|\n",
      "+--------------------+-----+-----------+----------+--------------------+--------------------+\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|[-0.8976748298773...| -0.8976748298773366|\n",
      "|     [-0.833333,0.0]|  0.0|  -0.833333|       0.0|[-1.5014897068013...| -1.5014897068013724|\n",
      "|[-0.444444,0.416667]|  0.0|  -0.444444|  0.416667|[-0.6561462706201...| -0.6561462706201501|\n",
      "|[-0.611111,0.0833...|  0.0|  -0.611111| 0.0833333|[-1.0184369357662...| -1.0184369357662864|\n",
      "|           [0.5,0.0]|  1.0|        0.5|       0.0|[1.39682909314878...|  1.3968290931487877|\n",
      "|      [0.166667,0.0]|  1.0|   0.166667|       0.0|[0.67224993659615...|  0.6722499365961586|\n",
      "|[0.444444,-0.0833...|  1.0|   0.444444|-0.0833334|[1.27606481352019...|  1.2760648135201946|\n",
      "|   [-0.333333,-0.75]|  1.0|  -0.333333|     -0.75|[-0.4146198851026...|-0.41461988510260694|\n",
      "|    [-0.555556,0.25]|  0.0|  -0.555556|      0.25|[-0.8976748298773...| -0.8976748298773366|\n",
      "|[-0.666667,-0.166...|  0.0|  -0.666667| -0.166667|[-1.1392012153948...| -1.1392012153948796|\n",
      "|     [-0.777778,0.0]|  0.0|  -0.777778|       0.0|[-1.3807276009124...| -1.3807276009124225|\n",
      "|[-0.833333,-0.083...|  0.0|  -0.833333|-0.0833334|[-1.5014897068013...| -1.5014897068013724|\n",
      "|[-0.611111,0.333333]|  0.0|  -0.611111|  0.333333|[-1.0184369357662...| -1.0184369357662864|\n",
      "|[-0.388889,0.583333]|  0.0|  -0.388889|  0.583333|[-0.5353841647312...| -0.5353841647312002|\n",
      "|[-0.833333,0.166667]|  0.0|  -0.833333|  0.166667|[-1.5014897068013...| -1.5014897068013724|\n",
      "|[-0.611111,0.166667]|  0.0|  -0.611111|  0.166667|[-1.0184369357662...| -1.0184369357662864|\n",
      "|   [0.0555554,-0.25]|  1.0|  0.0555554|     -0.25|[0.43072224683482...| 0.43072224683482946|\n",
      "|[-0.555556,-0.583...|  1.0|  -0.555556| -0.583333|[-0.8976748298773...| -0.8976748298773366|\n",
      "|[-0.222222,-0.333...|  1.0|  -0.222222| -0.333333|[-0.1730934995850...| -0.1730934995850639|\n",
      "|[0.111111,0.0833333]|  2.0|   0.111111| 0.0833333|[0.55148565696756...|  0.5514856569675654|\n",
      "+--------------------+-----+-----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisStandardizedLength = (standardScaler\n",
    "                              .fit(irisSeparateFeatures)\n",
    "                              .transform(irisSeparateFeatures)\n",
    "                              .withColumn('standadizedLength', getElement('standardized',lit(0))))\n",
    "irisStandardizedLength.show()                        \n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|summary|         sepalLength|   standadizedLength|\n",
      "+-------+--------------------+--------------------+\n",
      "|  count|                 150|                 150|\n",
      "|   mean|-0.14259263863153332|-4.73695157173400...|\n",
      "| stddev|  0.4600366943839747|                 1.0|\n",
      "|    min|                -1.0|  -1.863780371947509|\n",
      "|    max|                 1.0|  2.4836989148475532|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisStandardizedLength.describe('sepalLength','standadizedLength').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+------------------------------------------+\n",
      "|features              |label|featuresNorm                              |\n",
      "+----------------------+-----+------------------------------------------+\n",
      "|[-0.555556,0.5]       |0.0  |[-0.7432944123545073,0.6689644359475079]  |\n",
      "|[-0.833333,0.0]       |0.0  |[-1.0,0.0]                                |\n",
      "|[-0.444444,0.416667]  |0.0  |[-0.7295365898724013,0.6839417840996028]  |\n",
      "|[-0.611111,0.0833333] |0.0  |[-0.9908301719908108,0.13511317579222407] |\n",
      "|[0.5,0.0]             |1.0  |[1.0,0.0]                                 |\n",
      "|[0.166667,0.0]        |1.0  |[1.0,0.0]                                 |\n",
      "|[0.444444,-0.0833334] |1.0  |[0.9828721268491966,-0.1842888555038989]  |\n",
      "|[-0.333333,-0.75]     |1.0  |[-0.40613812690680956,-0.9138116993520209]|\n",
      "|[-0.555556,0.25]      |0.0  |[-0.9119216280284423,0.4103644043212756]  |\n",
      "|[-0.666667,-0.166667] |0.0  |[-0.970142414544513,-0.24253596743935182] |\n",
      "|[-0.777778,0.0]       |0.0  |[-1.0,0.0]                                |\n",
      "|[-0.833333,-0.0833334]|0.0  |[-0.9950371783877535,-0.09950383724328453]|\n",
      "|[-0.611111,0.333333]  |0.0  |[-0.8778957376151261,0.4788518287290899]  |\n",
      "|[-0.388889,0.583333]  |0.0  |[-0.5547005253880408,0.8320500748958752]  |\n",
      "|[-0.833333,0.166667]  |0.0  |[-0.9805805851756486,0.1961165877139989]  |\n",
      "|[-0.611111,0.166667]  |0.0  |[-0.9647636755110165,0.26311794012281664] |\n",
      "|[0.0555554,-0.25]     |1.0  |[0.21692987899703783,-0.9761871888107989] |\n",
      "|[-0.555556,-0.583333] |1.0  |[-0.6896556683748852,-0.7241374586902615] |\n",
      "|[-0.222222,-0.333333] |1.0  |[-0.5547001962252291,-0.8320502943378437] |\n",
      "|[0.111111,0.0833333]  |2.0  |[0.7999998271998313,0.6000002304001557]   |\n",
      "+----------------------+-----+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "normalizer = (Normalizer()\n",
    "                 .setInputCol('features')\n",
    "                 .setOutputCol('featuresNorm')\n",
    "                 .setP(2.0))\n",
    "irisNormalized = normalizer.transform(irisTwoFeatures)\n",
    "irisNormalized.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.743294412355,0.668964435948]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99999999999999989"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstVector = irisNormalized.select('featuresNorm').first()[0]\n",
    "print firstVector\n",
    "firstVector.norm(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|     featuresLength| featureNormLength|\n",
      "+-------------------+------------------+\n",
      "| 0.7474238885237748|0.9999999999999999|\n",
      "|           0.833333|               1.0|\n",
      "| 0.6092141315046787|               1.0|\n",
      "| 0.6167666440477224|               1.0|\n",
      "|                0.5|               1.0|\n",
      "|           0.166667|               1.0|\n",
      "| 0.4521890364566129|               1.0|\n",
      "| 0.8207380147702432|0.9999999999999999|\n",
      "| 0.6092146330612882|               1.0|\n",
      "| 0.6871846751623613|               1.0|\n",
      "|           0.777778|               1.0|\n",
      "| 0.8374893100479313|               1.0|\n",
      "|  0.696108858735471|0.9999999999999999|\n",
      "| 0.7010791989568653|               1.0|\n",
      "| 0.8498363241107078|               1.0|\n",
      "| 0.6334307722316622|               1.0|\n",
      "| 0.2560984234023318|0.9999999999999999|\n",
      "| 0.8055556206898442|0.9999999999999999|\n",
      "| 0.4006164077680793|               1.0|\n",
      "|0.13888878000000576|0.9999999999999999|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l2Norm = udf(lambda v: float(v.norm(2.0)), DoubleType())\n",
    "featureLengths = irisNormalized.select(l2Norm('features').alias('featuresLength'),\n",
    "                                       l2Norm('featuresNorm').alias('featureNormLength'))\n",
    "featureLengths.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------+\n",
      "|            features|label|sepalLength|sepalWidth|LengthFeatures|\n",
      "+--------------------+-----+-----------+----------+--------------+\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|           0.0|\n",
      "|     [-0.833333,0.0]|  0.0|  -0.833333|       0.0|           0.0|\n",
      "|[-0.444444,0.416667]|  0.0|  -0.444444|  0.416667|           1.0|\n",
      "|[-0.611111,0.0833...|  0.0|  -0.611111| 0.0833333|           0.0|\n",
      "|           [0.5,0.0]|  1.0|        0.5|       0.0|           3.0|\n",
      "|      [0.166667,0.0]|  1.0|   0.166667|       0.0|           2.0|\n",
      "|[0.444444,-0.0833...|  1.0|   0.444444|-0.0833334|           2.0|\n",
      "|   [-0.333333,-0.75]|  1.0|  -0.333333|     -0.75|           1.0|\n",
      "|    [-0.555556,0.25]|  0.0|  -0.555556|      0.25|           0.0|\n",
      "|[-0.666667,-0.166...|  0.0|  -0.666667| -0.166667|           0.0|\n",
      "|     [-0.777778,0.0]|  0.0|  -0.777778|       0.0|           0.0|\n",
      "|[-0.833333,-0.083...|  0.0|  -0.833333|-0.0833334|           0.0|\n",
      "|[-0.611111,0.333333]|  0.0|  -0.611111|  0.333333|           0.0|\n",
      "|[-0.388889,0.583333]|  0.0|  -0.388889|  0.583333|           1.0|\n",
      "|[-0.833333,0.166667]|  0.0|  -0.833333|  0.166667|           0.0|\n",
      "|[-0.611111,0.166667]|  0.0|  -0.611111|  0.166667|           0.0|\n",
      "|   [0.0555554,-0.25]|  1.0|  0.0555554|     -0.25|           2.0|\n",
      "|[-0.555556,-0.583...|  1.0|  -0.555556| -0.583333|           0.0|\n",
      "|[-0.222222,-0.333...|  1.0|  -0.222222| -0.333333|           1.0|\n",
      "|[0.111111,0.0833333]|  2.0|   0.111111| 0.0833333|           2.0|\n",
      "+--------------------+-----+-----------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "splits = [-float('inf'), -.5, 0.0, .5, float('inf')]\n",
    "lengthBucketizer = (Bucketizer()\n",
    "                       .setInputCol('sepalLength')\n",
    "                       .setOutputCol('LengthFeatures')\n",
    "                       .setSplits(splits))\n",
    "irisBucketizdLength = lengthBucketizer.transform(irisSeparateFeatures)\n",
    "irisBucketizdLength.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------+-------------+\n",
      "|            features|label|sepalLength|sepalWidth|LengthFeatures|widthFeatures|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|           0.0|          3.0|\n",
      "|     [-0.833333,0.0]|  0.0|  -0.833333|       0.0|           0.0|          2.0|\n",
      "|[-0.444444,0.416667]|  0.0|  -0.444444|  0.416667|           1.0|          2.0|\n",
      "|[-0.611111,0.0833...|  0.0|  -0.611111| 0.0833333|           0.0|          2.0|\n",
      "|           [0.5,0.0]|  1.0|        0.5|       0.0|           3.0|          2.0|\n",
      "|      [0.166667,0.0]|  1.0|   0.166667|       0.0|           2.0|          2.0|\n",
      "|[0.444444,-0.0833...|  1.0|   0.444444|-0.0833334|           2.0|          1.0|\n",
      "|   [-0.333333,-0.75]|  1.0|  -0.333333|     -0.75|           1.0|          0.0|\n",
      "|    [-0.555556,0.25]|  0.0|  -0.555556|      0.25|           0.0|          2.0|\n",
      "|[-0.666667,-0.166...|  0.0|  -0.666667| -0.166667|           0.0|          1.0|\n",
      "|     [-0.777778,0.0]|  0.0|  -0.777778|       0.0|           0.0|          2.0|\n",
      "|[-0.833333,-0.083...|  0.0|  -0.833333|-0.0833334|           0.0|          1.0|\n",
      "|[-0.611111,0.333333]|  0.0|  -0.611111|  0.333333|           0.0|          2.0|\n",
      "|[-0.388889,0.583333]|  0.0|  -0.388889|  0.583333|           1.0|          3.0|\n",
      "|[-0.833333,0.166667]|  0.0|  -0.833333|  0.166667|           0.0|          2.0|\n",
      "|[-0.611111,0.166667]|  0.0|  -0.611111|  0.166667|           0.0|          2.0|\n",
      "|   [0.0555554,-0.25]|  1.0|  0.0555554|     -0.25|           2.0|          1.0|\n",
      "|[-0.555556,-0.583...|  1.0|  -0.555556| -0.583333|           0.0|          0.0|\n",
      "|[-0.222222,-0.333...|  1.0|  -0.222222| -0.333333|           1.0|          1.0|\n",
      "|[0.111111,0.0833333]|  2.0|   0.111111| 0.0833333|           2.0|          2.0|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "widthBucketizer = (Bucketizer()\n",
    "                   .setInputCol(\"sepalWidth\")\n",
    "                   .setOutputCol(\"widthFeatures\")\n",
    "                   .setSplits(splits))\n",
    "\n",
    "irisBucketizedWidth = widthBucketizer.transform(irisBucketizdLength)\n",
    "irisBucketizedWidth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------+-------------+\n",
      "|            features|label|sepalLength|sepalWidth|LengthFeatures|widthFeatures|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|           0.0|          3.0|\n",
      "|     [-0.833333,0.0]|  0.0|  -0.833333|       0.0|           0.0|          2.0|\n",
      "|[-0.444444,0.416667]|  0.0|  -0.444444|  0.416667|           1.0|          2.0|\n",
      "|[-0.611111,0.0833...|  0.0|  -0.611111| 0.0833333|           0.0|          2.0|\n",
      "|           [0.5,0.0]|  1.0|        0.5|       0.0|           3.0|          2.0|\n",
      "|      [0.166667,0.0]|  1.0|   0.166667|       0.0|           2.0|          2.0|\n",
      "|[0.444444,-0.0833...|  1.0|   0.444444|-0.0833334|           2.0|          1.0|\n",
      "|   [-0.333333,-0.75]|  1.0|  -0.333333|     -0.75|           1.0|          0.0|\n",
      "|    [-0.555556,0.25]|  0.0|  -0.555556|      0.25|           0.0|          2.0|\n",
      "|[-0.666667,-0.166...|  0.0|  -0.666667| -0.166667|           0.0|          1.0|\n",
      "|     [-0.777778,0.0]|  0.0|  -0.777778|       0.0|           0.0|          2.0|\n",
      "|[-0.833333,-0.083...|  0.0|  -0.833333|-0.0833334|           0.0|          1.0|\n",
      "|[-0.611111,0.333333]|  0.0|  -0.611111|  0.333333|           0.0|          2.0|\n",
      "|[-0.388889,0.583333]|  0.0|  -0.388889|  0.583333|           1.0|          3.0|\n",
      "|[-0.833333,0.166667]|  0.0|  -0.833333|  0.166667|           0.0|          2.0|\n",
      "|[-0.611111,0.166667]|  0.0|  -0.611111|  0.166667|           0.0|          2.0|\n",
      "|   [0.0555554,-0.25]|  1.0|  0.0555554|     -0.25|           2.0|          1.0|\n",
      "|[-0.555556,-0.583...|  1.0|  -0.555556| -0.583333|           0.0|          0.0|\n",
      "|[-0.222222,-0.333...|  1.0|  -0.222222| -0.333333|           1.0|          1.0|\n",
      "|[0.111111,0.0833333]|  2.0|   0.111111| 0.0833333|           2.0|          2.0|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "pipelineBucketizer = Pipeline().setStages([lengthBucketizer,widthBucketizer])\n",
    "pipelineModelBucketizer = pipelineBucketizer.fit(irisSeparateFeatures)\n",
    "irisBucketized = pipelineModelBucketizer.transform(irisSeparateFeatures)\n",
    "\n",
    "irisBucketized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCols: input column names. (undefined)\n",
      "outputCol: output column name. (default: VectorAssembler_42788cc46693f91c1eea__output)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "pipeline = Pipeline()\n",
    "assembler = VectorAssembler()\n",
    "\n",
    "print assembler.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------+-------------+------------------+\n",
      "|            features|label|sepalLength|sepalWidth|LengthFeatures|widthFeatures|featuresBucketized|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+------------------+\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|           0.0|          3.0|         [0.0,3.0]|\n",
      "|     [-0.833333,0.0]|  0.0|  -0.833333|       0.0|           0.0|          2.0|         [0.0,2.0]|\n",
      "|[-0.444444,0.416667]|  0.0|  -0.444444|  0.416667|           1.0|          2.0|         [1.0,2.0]|\n",
      "|[-0.611111,0.0833...|  0.0|  -0.611111| 0.0833333|           0.0|          2.0|         [0.0,2.0]|\n",
      "|           [0.5,0.0]|  1.0|        0.5|       0.0|           3.0|          2.0|         [3.0,2.0]|\n",
      "|      [0.166667,0.0]|  1.0|   0.166667|       0.0|           2.0|          2.0|         [2.0,2.0]|\n",
      "|[0.444444,-0.0833...|  1.0|   0.444444|-0.0833334|           2.0|          1.0|         [2.0,1.0]|\n",
      "|   [-0.333333,-0.75]|  1.0|  -0.333333|     -0.75|           1.0|          0.0|         [1.0,0.0]|\n",
      "|    [-0.555556,0.25]|  0.0|  -0.555556|      0.25|           0.0|          2.0|         [0.0,2.0]|\n",
      "|[-0.666667,-0.166...|  0.0|  -0.666667| -0.166667|           0.0|          1.0|         [0.0,1.0]|\n",
      "|     [-0.777778,0.0]|  0.0|  -0.777778|       0.0|           0.0|          2.0|         [0.0,2.0]|\n",
      "|[-0.833333,-0.083...|  0.0|  -0.833333|-0.0833334|           0.0|          1.0|         [0.0,1.0]|\n",
      "|[-0.611111,0.333333]|  0.0|  -0.611111|  0.333333|           0.0|          2.0|         [0.0,2.0]|\n",
      "|[-0.388889,0.583333]|  0.0|  -0.388889|  0.583333|           1.0|          3.0|         [1.0,3.0]|\n",
      "|[-0.833333,0.166667]|  0.0|  -0.833333|  0.166667|           0.0|          2.0|         [0.0,2.0]|\n",
      "|[-0.611111,0.166667]|  0.0|  -0.611111|  0.166667|           0.0|          2.0|         [0.0,2.0]|\n",
      "|   [0.0555554,-0.25]|  1.0|  0.0555554|     -0.25|           2.0|          1.0|         [2.0,1.0]|\n",
      "|[-0.555556,-0.583...|  1.0|  -0.555556| -0.583333|           0.0|          0.0|         (2,[],[])|\n",
      "|[-0.222222,-0.333...|  1.0|  -0.222222| -0.333333|           1.0|          1.0|         [1.0,1.0]|\n",
      "|[0.111111,0.0833333]|  2.0|   0.111111| 0.0833333|           2.0|          2.0|         [2.0,2.0]|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(assembler\n",
    "     .setInputCols(['LengthFeatures','widthFeatures'])\n",
    "     .setOutputCol('featuresBucketized'))\n",
    "pipeline.setStages([lengthBucketizer,widthBucketizer, assembler])\n",
    "irisAssembled = pipeline.fit(irisSeparateFeatures).transform(irisSeparateFeatures)\n",
    "irisAssembled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|   50|\n",
      "|  1.0|   50|\n",
      "|  2.0|   50|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisSeparateFeatures.groupby('label').count().orderBy('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|   50|\n",
      "|  1.0|   50|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "irisTwoClass = irisSeparateFeatures.filter(col('label')<2)\n",
    "irisTwoClass.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item in train dataset:70\n",
      "Item in test dataset:30\n"
     ]
    }
   ],
   "source": [
    "irisTest, irisTrain = irisTwoClass.randomSplit([.25, .75], seed=0)\n",
    "irisTest.cache()\n",
    "irisTrain.cache()\n",
    "\n",
    "print 'Item in train dataset:{0}'.format(irisTrain.count())\n",
    "print 'Item in test dataset:{0}'.format(irisTest.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------+----------+\n",
      "|label|probability                               |prediction|\n",
      "+-----+------------------------------------------+----------+\n",
      "|0.0  |[0.9999999999914739,8.526040450948622E-12]|0.0       |\n",
      "|1.0  |[2.453432149811593E-22,1.0]               |1.0       |\n",
      "|1.0  |[1.918375289718597E-11,0.9999999999808162]|1.0       |\n",
      "|1.0  |[1.2659797057529866E-27,1.0]              |1.0       |\n",
      "|1.0  |[1.6190759585416815E-38,1.0]              |1.0       |\n",
      "|1.0  |[3.71774215018083E-6,0.9999962822578499]  |1.0       |\n",
      "|0.0  |[0.999996560002663,3.4399973370201116E-6] |0.0       |\n",
      "|1.0  |[3.71774215018083E-6,0.9999962822578499]  |1.0       |\n",
      "|0.0  |[0.9999999999914739,8.526040450948622E-12]|0.0       |\n",
      "|0.0  |[0.6000010126279576,0.39999898737204237]  |0.0       |\n",
      "+-----+------------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = (LogisticRegression()\n",
    "         .setFeaturesCol('featuresBucketized')\n",
    "         .setRegParam(0.0)\n",
    "         .setLabelCol('label')\n",
    "         .setMaxIter(1000))\n",
    "pipeline.setStages([lengthBucketizer, widthBucketizer, assembler, lr])\n",
    "\n",
    "pipelineModelLR = pipeline.fit(irisTrain)\n",
    "\n",
    "irisTestPredictions = (pipelineModelLR\n",
    "                          .transform(irisTest)\n",
    "                          .cache())\n",
    "irisTestPredictions.select('label','probability','prediction').show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "oneHotLength = (OneHotEncoder()\n",
    "                   .setInputCol('LengthFeatures')\n",
    "                   .setOutputCol('lengthOneHot'))\n",
    "pipeline.setStages([lengthBucketizer, widthBucketizer, oneHotLength])\n",
    "irisWithOneHotLength = pipeline.fit(irisTrain).transform(irisTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------+-------------+-------------+\n",
      "|            features|label|sepalLength|sepalWidth|LengthFeatures|widthFeatures| lengthOneHot|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+-------------+\n",
      "|[-0.833333,-0.083...|  0.0|  -0.833333|-0.0833334|           0.0|          1.0|(3,[0],[1.0])|\n",
      "|     [-0.833333,0.0]|  0.0|  -0.833333|       0.0|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|[-0.833333,0.166667]|  0.0|  -0.833333|  0.166667|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|     [-0.777778,0.0]|  0.0|  -0.777778|       0.0|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|[-0.666667,-0.166...|  0.0|  -0.666667| -0.166667|           0.0|          1.0|(3,[0],[1.0])|\n",
      "|[-0.611111,0.0833...|  0.0|  -0.611111| 0.0833333|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|[-0.611111,0.166667]|  0.0|  -0.611111|  0.166667|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|[-0.611111,0.333333]|  0.0|  -0.611111|  0.333333|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|[-0.555556,-0.583...|  1.0|  -0.555556| -0.583333|           0.0|          0.0|(3,[0],[1.0])|\n",
      "|    [-0.555556,0.25]|  0.0|  -0.555556|      0.25|           0.0|          2.0|(3,[0],[1.0])|\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|           0.0|          3.0|(3,[0],[1.0])|\n",
      "|[-0.444444,0.416667]|  0.0|  -0.444444|  0.416667|           1.0|          2.0|(3,[1],[1.0])|\n",
      "|[-0.388889,-0.166...|  1.0|  -0.388889| -0.166667|           1.0|          1.0|(3,[1],[1.0])|\n",
      "|   [-0.333333,-0.75]|  1.0|  -0.333333|     -0.75|           1.0|          0.0|(3,[1],[1.0])|\n",
      "|[-0.222222,-0.333...|  1.0|  -0.222222| -0.333333|           1.0|          1.0|(3,[1],[1.0])|\n",
      "|[-0.0555556,-0.41...|  1.0| -0.0555556| -0.416667|           1.0|          1.0|(3,[1],[1.0])|\n",
      "|[-0.0555556,0.166...|  1.0| -0.0555556|  0.166667|           1.0|          2.0|(3,[1],[1.0])|\n",
      "|      [0.166667,0.0]|  1.0|   0.166667|       0.0|           2.0|          2.0|(3,[2],[1.0])|\n",
      "|[0.333333,-0.0833...|  1.0|   0.333333|-0.0833334|           2.0|          1.0|(3,[2],[1.0])|\n",
      "|[0.444444,-0.0833...|  1.0|   0.444444|-0.0833334|           2.0|          1.0|(3,[2],[1.0])|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisWithOneHotLength.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotWidth = (OneHotEncoder()\n",
    "               .setInputCol('widthFeatures')\n",
    "               .setOutputCol('widthOneHot'))\n",
    "\n",
    "assembleOneHot = (VectorAssembler()\n",
    "                  .setInputCols(['lengthOneHot', 'widthOneHot'])\n",
    "                  .setOutputCol('featuresBucketized'))\n",
    "\n",
    "pipeline.setStages([lengthBucketizer, widthBucketizer, oneHotLength, oneHotWidth, assembleOneHot])\n",
    "irisWithOneHot = pipeline.fit(irisTrain).transform(irisTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------------+\n",
      "| lengthOneHot|  widthOneHot| featuresBucketized|\n",
      "+-------------+-------------+-------------------+\n",
      "|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[0],[1.0])|(6,[0,3],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|(3,[0],[1.0])|    (3,[],[])|      (6,[0],[1.0])|\n",
      "|(3,[1],[1.0])|(3,[2],[1.0])|(6,[1,5],[1.0,1.0])|\n",
      "|(3,[1],[1.0])|(3,[1],[1.0])|(6,[1,4],[1.0,1.0])|\n",
      "|(3,[1],[1.0])|(3,[0],[1.0])|(6,[1,3],[1.0,1.0])|\n",
      "|(3,[1],[1.0])|(3,[1],[1.0])|(6,[1,4],[1.0,1.0])|\n",
      "|(3,[1],[1.0])|(3,[1],[1.0])|(6,[1,4],[1.0,1.0])|\n",
      "|(3,[1],[1.0])|(3,[2],[1.0])|(6,[1,5],[1.0,1.0])|\n",
      "|(3,[2],[1.0])|(3,[2],[1.0])|(6,[2,5],[1.0,1.0])|\n",
      "|(3,[2],[1.0])|(3,[1],[1.0])|(6,[2,4],[1.0,1.0])|\n",
      "|(3,[2],[1.0])|(3,[1],[1.0])|(6,[2,4],[1.0,1.0])|\n",
      "+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisWithOneHot.select('lengthOneHot', 'widthOneHot','featuresBucketized').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------+----------+--------------+-------------+-------------+-------------+-------------------+--------------------+--------------------+----------+\n",
      "|            features|label|sepalLength|sepalWidth|LengthFeatures|widthFeatures| lengthOneHot|  widthOneHot| featuresBucketized|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+-------------+-------------+-------------------+--------------------+--------------------+----------+\n",
      "|[-0.388889,0.583333]|  0.0|  -0.388889|  0.583333|           1.0|          3.0|(3,[1],[1.0])|    (3,[],[])|      (6,[1],[1.0])|[19.4146216417010...|[0.99999999629884...|       0.0|\n",
      "|[-0.333333,-0.583...|  1.0|  -0.333333| -0.583333|           1.0|          0.0|(3,[1],[1.0])|(3,[0],[1.0])|(6,[1,3],[1.0,1.0])|[-56.974613634311...|[1.80401311314184...|       1.0|\n",
      "|[-0.277778,-0.166...|  1.0|  -0.277778| -0.166667|           1.0|          1.0|(3,[1],[1.0])|(3,[1],[1.0])|(6,[1,4],[1.0,1.0])|[-19.241810745489...|[4.39934245212316...|       1.0|\n",
      "|   [0.0555554,-0.25]|  1.0|  0.0555554|     -0.25|           2.0|          1.0|(3,[2],[1.0])|(3,[1],[1.0])|(6,[2,4],[1.0,1.0])|[-63.619205468647...|[2.34709204719495...|       1.0|\n",
      "|    [0.111111,-0.75]|  1.0|   0.111111|     -0.75|           2.0|          0.0|(3,[2],[1.0])|(3,[0],[1.0])|(6,[2,3],[1.0,1.0])|[-101.35200835746...|[9.62458562465300...|       1.0|\n",
      "|[-0.666667,-0.666...|  1.0|  -0.666667| -0.666667|           0.0|          0.0|(3,[0],[1.0])|(3,[0],[1.0])|(6,[0,3],[1.0,1.0])|[-20.649240407902...|[1.07683418685194...|       1.0|\n",
      "|[-0.666667,-0.083...|  0.0|  -0.666667|-0.0833334|           0.0|          1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|[17.0835624809188...|[0.99999996191946...|       0.0|\n",
      "|    [-0.611111,-1.0]|  1.0|  -0.611111|      -1.0|           0.0|          0.0|(3,[0],[1.0])|(3,[0],[1.0])|(6,[0,3],[1.0,1.0])|[-20.649240407902...|[1.07683418685194...|       1.0|\n",
      "|         [-0.5,0.75]|  0.0|       -0.5|      0.75|           1.0|          3.0|(3,[1],[1.0])|    (3,[],[])|      (6,[1],[1.0])|[19.4146216417010...|[0.99999999629884...|       0.0|\n",
      "|    [-0.333333,0.25]|  0.0|  -0.333333|      0.25|           1.0|          2.0|(3,[1],[1.0])|(3,[2],[1.0])|(6,[1,5],[1.0,1.0])|[0.40546431121075...|[0.59999980874460...|       0.0|\n",
      "|[-0.111111,-0.166...|  1.0|  -0.111111| -0.166667|           1.0|          1.0|(3,[1],[1.0])|(3,[1],[1.0])|(6,[1,4],[1.0,1.0])|[-19.241810745489...|[4.39934245212316...|       1.0|\n",
      "|[-0.0555556,-0.83...|  1.0| -0.0555556| -0.833333|           1.0|          0.0|(3,[1],[1.0])|(3,[0],[1.0])|(6,[1,3],[1.0,1.0])|[-56.974613634311...|[1.80401311314184...|       1.0|\n",
      "|   [-0.944444,-0.25]|  0.0|  -0.944444|     -0.25|           0.0|          1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|[17.0835624809188...|[0.99999996191946...|       0.0|\n",
      "|[-0.555556,0.416667]|  0.0|  -0.555556|  0.416667|           0.0|          2.0|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|[36.7308375376193...|[0.99999999999999...|       0.0|\n",
      "|     [-0.555556,0.5]|  0.0|  -0.555556|       0.5|           0.0|          3.0|(3,[0],[1.0])|    (3,[],[])|      (6,[0],[1.0])|[55.7399948681097...|[1.0,6.2005156425...|       0.0|\n",
      "|[-0.388889,0.416667]|  0.0|  -0.388889|  0.416667|           1.0|          2.0|(3,[1],[1.0])|(3,[2],[1.0])|(6,[1,5],[1.0,1.0])|[0.40546431121075...|[0.59999980874460...|       0.0|\n",
      "|[-0.333333,-0.666...|  1.0|  -0.333333| -0.666667|           1.0|          0.0|(3,[1],[1.0])|(3,[0],[1.0])|(6,[1,3],[1.0,1.0])|[-56.974613634311...|[1.80401311314184...|       1.0|\n",
      "|[-0.277778,-0.583...|  1.0|  -0.277778| -0.583333|           1.0|          0.0|(3,[1],[1.0])|(3,[0],[1.0])|(6,[1,3],[1.0,1.0])|[-56.974613634311...|[1.80401311314184...|       1.0|\n",
      "|[-0.166667,0.666667]|  0.0|  -0.166667|  0.666667|           1.0|          3.0|(3,[1],[1.0])|    (3,[],[])|      (6,[1],[1.0])|[19.4146216417010...|[0.99999999629884...|       0.0|\n",
      "|[0.111111,-0.583333]|  1.0|   0.111111| -0.583333|           2.0|          0.0|(3,[2],[1.0])|(3,[0],[1.0])|(6,[2,3],[1.0,1.0])|[-101.35200835746...|[9.62458562465300...|       1.0|\n",
      "+--------------------+-----+-----------+----------+--------------+-------------+-------------+-------------+-------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.setStages([lengthBucketizer, widthBucketizer, oneHotLength, oneHotWidth, assembleOneHot, lr])\n",
    "pipelineModelLR2 = pipeline.fit(irisTrain)\n",
    "\n",
    "irisTestPredictions2 = (pipelineModelLR2\n",
    "                        .transform(irisTest)\n",
    "                        .cache())\n",
    "irisTestPredictions2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.83727483566\n",
      "[-51.9027200324,-15.577346806,28.8000479171,76.389235276,38.6564323872,19.0091573305]\n"
     ]
    }
   ],
   "source": [
    "logisticModel = pipelineModelLR2.stages[-1]\n",
    "print logisticModel.intercept\n",
    "print logisticModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelOneAccuracy:0.967\n",
      "modelTwoAccuracy:0.967\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def modelAccuracy(df):\n",
    "    return (df\n",
    "               .select((col('prediction') == col('label')).cast('int').alias('correct'))\n",
    "               .groupby()\n",
    "               .avg('correct')\n",
    "               .first()[0])\n",
    "\n",
    "modelOneAccuracy = modelAccuracy(irisTestPredictions)\n",
    "modelTwoAccuracy = modelAccuracy(irisTestPredictions2)\n",
    "\n",
    "print 'modelOneAccuracy:{0:.3f}'.format(modelOneAccuracy)\n",
    "print 'modelTwoAccuracy:{0:.3f}'.format(modelTwoAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|avg(CAST((prediction = label) AS INT))|\n",
      "+--------------------------------------+\n",
      "|                    0.9666666666666667|\n",
      "+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisTestPredictions.registerTempTable('modelOnePredictions')\n",
    "sqlResult = sqlContext.sql('select avg(int(prediction == label)) from modelOnePredictions')\n",
    "sqlResult.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First model AUC: 0.996\n",
      "Second model AUC: 0.973\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "binaryEvaluator = (BinaryClassificationEvaluator()\n",
    "                      .setRawPredictionCol('rawPrediction')\n",
    "                      .setMetricName('areaUnderROC'))\n",
    "firstModelTestAUC = binaryEvaluator.evaluate(irisTestPredictions)\n",
    "secondModelTestAUC = binaryEvaluator.evaluate(irisTestPredictions2)\n",
    "\n",
    "print 'First model AUC: {0:.3f}'.format(firstModelTestAUC)\n",
    "print 'Second model AUC: {0:.3f}'.format(secondModelTestAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First model training AUC: 0.998\n",
      "Second model training AUC: 0.998\n"
     ]
    }
   ],
   "source": [
    "irisTrainPredictions = pipelineModelLR.transform(irisTrain)\n",
    "irisTrainPredictions2 = pipelineModelLR2.transform(irisTrain)\n",
    "\n",
    "firstModelTrainAUC = binaryEvaluator.evaluate(irisTrainPredictions)\n",
    "secondModelTrainAUC = binaryEvaluator.evaluate(irisTrainPredictions2)\n",
    "\n",
    "print '\\nFirst model training AUC: {0:.3f}'.format(firstModelTrainAUC)\n",
    "print 'Second model training AUC: {0:.3f}'.format(secondModelTrainAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model one precision: 0.967\n",
      "Model two precision: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "metric = 'precision'\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator()\n",
    "\n",
    "#multiclassEval.setMetricName(metric)\n",
    "print 'Model one {0}: {1:.3f}'.format(metric, multiclassEval.evaluate(irisTestPredictions))\n",
    "print 'Model two {0}: {1:.3f}\\n'.format(metric, multiclassEval.evaluate(irisTestPredictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labelCol: label column name. (default: label)\\nmetricName: metric name in evaluation (f1|weightedPrecision|weightedRecall|accuracy) (default: f1, current: precision)\\npredictionCol: prediction column name. (default: prediction)'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
